{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yahoofinance 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "import time\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 티커 배열\n",
    "tickers = ['SOXL']  # 예시로 몇 가지 티커 추가\n",
    "\n",
    "\n",
    "# 크롬 웹드라이버 설정\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "# 결과를 저장할 CSV 파일 설정\n",
    "output_file = \"news_results.csv\"\n",
    "\n",
    "# CSV 파일의 헤더 작성\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Ticker\", \"Date\", \"Title\", \"Link\", \"Content\"])\n",
    "\n",
    "# 뉴스 크롤링 함수\n",
    "def crawl_news_for_ticker(ticker):\n",
    "    url = f\"https://finance.yahoo.com/quote/{ticker}/news/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # 페이지 로딩 대기\n",
    "\n",
    "    # 뉴스 항목 추출\n",
    "    try:\n",
    "        news_items = driver.find_elements(By.XPATH, '//li[@class=\"stream-item story-item yf-1usaaz9\"]')\n",
    "        print(f\"Ticker: {ticker} - 뉴스 제목 및 내용:\")\n",
    "\n",
    "        # 각 뉴스 기사에 대해 처리\n",
    "        for item in news_items:\n",
    "            # 뉴스 제목 추출\n",
    "            title_element = item.find_element(By.XPATH, './/h3[@class=\"clamp  yf-1sxfjua\"]')\n",
    "            title = title_element.text\n",
    "            print(f\"\\n- 제목: {title}\")\n",
    "\n",
    "            # 뉴스 기사 링크 추출\n",
    "            link_element = item.find_element(By.XPATH, './/div[@class=\"content yf-1sxfjua\"]//a[@class=\"subtle-link fin-size-small titles noUnderline yf-1e4diqp\"]')\n",
    "            news_link = link_element.get_attribute('href')\n",
    "            print(f\"링크: {news_link}\")\n",
    "\n",
    "            # 뉴스 기사 본문 및 작성일 크롤링\n",
    "            driver.execute_script(f\"window.open('{news_link}', '_blank');\")\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "            time.sleep(3)  # 새 탭이 열리고 내용이 로드되도록 대기\n",
    "\n",
    "            # 뉴스 내용 크롤링\n",
    "            try:\n",
    "                content = driver.find_element(By.XPATH, '//*[@id=\"nimbus-app\"]/section/section/section/article/div/div[1]/div[3]/div[2]').text\n",
    "                print(f\"내용: {content[:500]}...\")  # 내용이 길 경우 앞부분만 출력\n",
    "            except:\n",
    "                content = \"내용을 가져오지 못했습니다.\"\n",
    "                print(content)\n",
    "\n",
    "            # 작성일 크롤링 및 datetime 형식 변환\n",
    "            \n",
    "            time.sleep(3)\n",
    "\n",
    "            date_element = driver.find_element(By.XPATH, '//time[@class=\"byline-attr-meta-time\"]')\n",
    "            date_raw = date_element.get_attribute('datetime')  # 원본 날짜 값 가져오기\n",
    "            date = datetime.strptime(date_raw, '%Y-%m-%dT%H:%M:%S.%fZ').strftime('%Y-%m-%d')  # datetime 형식 변환\n",
    "            print(f\"작성일: {date}\")\n",
    "\n",
    "            print(date)\n",
    "\n",
    "            # 결과를 CSV 파일에 저장\n",
    "            with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([ticker, date, title, news_link, content])  # 내용 전체 저장\n",
    "\n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[0])  # 원래 탭으로 돌아옴\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving news for {ticker}: {str(e)}\")\n",
    "\n",
    "# 각 티커에 대해 뉴스 제목 및 내용 크롤링\n",
    "for ticker in tickers:\n",
    "    crawl_news_for_ticker(ticker)\n",
    "\n",
    "# 브라우저 종료\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
